{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6568b665",
   "metadata": {},
   "source": [
    "## Subcategory SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7b8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn import svm as sksvm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import sklearn\n",
    "import joblib\n",
    "import dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e173b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "HF_TOKEN = os.environ['HF_TOKEN']\n",
    "SEED = 42\n",
    "TRAINING = True\n",
    "datasetTotal = datasets.load_dataset('sapienzanlp/nlp2025_hw1_cultural_dataset', token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73ecee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "valSet = pd.DataFrame(datasetTotal['validation'])[['subcategory', 'label', 'category','type']]\n",
    "trainSet = pd.DataFrame(datasetTotal['train'])[['subcategory', 'label', 'category', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48527f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "{'book': 0, 'cooking technique': 1, 'river': 2, 'religion': 3, 'archive': 4, 'comics artist': 5, 'station': 6, 'art gallery': 7, 'television': 8, 'environment': 9, 'sports equipment': 10, 'choreographer': 11, 'dance': 12, 'mountain': 13, 'comics': 14, 'city': 15, 'biologist': 16, 'theatrical genre': 17, 'photographer': 18, 'cook': 19, 'construction': 20, 'museum': 21, 'painting': 22, 'clothing': 23, 'happening': 24, 'film producer': 25, 'tradition': 26, 'traditional costume': 27, 'building material': 28, 'automobile manufacturer': 29, 'food': 30, 'model': 31, 'ingredient': 32, 'film genre': 33, 'non-fiction writer': 34, 'folk dance': 35, 'record label': 36, 'historical event': 37, 'artist': 38, 'writing style': 39, 'media company': 40, 'athlete': 41, 'architect': 42, 'transport company': 43, 'government': 44, 'transport': 45, 'film': 46, 'animal': 47, 'tree': 48, 'philosopher': 49, 'poet': 50, 'sports team': 51, 'film studio': 52, 'mores': 53, 'magazine': 54, 'neighborhood': 55, 'gesture': 56, 'animation technique': 57, 'acting style': 58, 'musician': 59, 'poetry': 60, 'literary genre': 61, 'monument': 62, 'music genre': 63, 'sports club': 64, 'recurring sporting event': 65, 'architectural style': 66, 'animation studio': 67, 'actor': 68, 'streaming service': 69, 'visual arts': 70, 'philosophy': 71, 'architectural structure': 72, 'building': 73, 'religious leader': 74, 'publisher': 75, 'designer': 76, 'body language': 77, 'government agency': 78, 'sport': 79, 'animated film': 80, 'fish': 81, 'theatrical director': 82, 'religious movement': 83, 'film festival': 84, 'manga': 85, 'politician': 86, 'geographic location': 87, 'drink': 88, 'literary award': 89, 'textile': 90, 'religious book': 91, 'greeting': 92, 'bookstore': 93, 'organism': 94, 'policy': 95, 'musical group': 96, 'writer': 97, 'fashion trend': 98, 'film director': 99, 'musical profession': 100, 'political party': 101, 'ritual': 102, 'mode of transport': 103, 'music festival': 104, 'art movement': 105, 'philosophical movement': 106, 'historian': 107, 'dish': 108, 'law': 109, 'plant': 110, 'production company': 111}\n",
      "19\n",
      "{'geography': 0, 'history': 1, 'films': 2, 'books': 3, 'literature': 4, 'biology': 5, 'philosophy and religion': 6, 'music': 7, 'media': 8, 'gestures and habits': 9, 'fashion': 10, 'comics and anime': 11, 'performing arts': 12, 'architecture': 13, 'visual arts': 14, 'politics': 15, 'transportation': 16, 'sports': 17, 'food': 18}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "subcatTrain = set(trainSet['subcategory'])\n",
    "subcatVal = set(valSet['subcategory'])\n",
    "\n",
    "subcat = subcatTrain.union(subcatVal)\n",
    "print(len(subcat))\n",
    "aliasesSub = {k:i for i,k in enumerate(subcat)}\n",
    "print(aliasesSub)\n",
    "\n",
    "catTrain = set(trainSet['category'])\n",
    "catVal = set(valSet['category'])\n",
    "\n",
    "cat = catTrain.union(catVal)\n",
    "print(len(cat))\n",
    "\n",
    "aliasesCat = {k:i for i,k in enumerate(cat)}\n",
    "print(aliasesCat)\n",
    "\n",
    "typeTrain = set(trainSet['type'])\n",
    "typeVal = set(valSet['type'])\n",
    "\n",
    "typeTot = typeTrain.union(typeVal)\n",
    "aliasesType = {k:i for i,k in enumerate(typeTot)}\n",
    "print(len(typeTot))\n",
    "aliasLabel = {\n",
    "    'cultural exclusive':0,\n",
    "    'cultural agnostic':1,\n",
    "    'cultural representative':2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa7a3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6251, 133)\n"
     ]
    }
   ],
   "source": [
    "subCategoryEncodingTrain = np.zeros((trainSet.shape[0], len(subcat)), dtype=int)\n",
    "categoryEncodingTrain = np.zeros((trainSet.shape[0], len(cat)), dtype=int)\n",
    "typeEncodingTrain = np.zeros((trainSet.shape[0], len(typeTot)), dtype=int)\n",
    "\n",
    "finalTrainLabel = trainSet['label'].apply(lambda x: aliasLabel[x])\n",
    "\n",
    "for i in range(trainSet.shape[0]):\n",
    "    subCategoryEncodingTrain[i][aliasesSub[trainSet['subcategory'].iloc[i]]] = 1\n",
    "    categoryEncodingTrain[i][aliasesCat[trainSet['category'].iloc[i]]] = 1\n",
    "    typeEncodingTrain[i][aliasesType[trainSet['type'].iloc[i]]] = 1\n",
    "    \n",
    "finalTrainData = np.concatenate((subCategoryEncodingTrain, categoryEncodingTrain, typeEncodingTrain), axis=1)\n",
    "print(finalTrainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2862dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 133)\n"
     ]
    }
   ],
   "source": [
    "subCategoryEncodingVal = np.zeros((valSet.shape[0], len(subcat)), dtype=int)\n",
    "categoryEncodingVal = np.zeros((valSet.shape[0], len(cat)), dtype=int)\n",
    "typeEncodingVal = np.zeros((valSet.shape[0], len(typeTot)), dtype=int)\n",
    "\n",
    "finalValLabel = valSet['label'].apply(lambda x: aliasLabel[x])\n",
    "\n",
    "for i in range(valSet.shape[0]):\n",
    "    subCategoryEncodingVal[i][aliasesSub[valSet['subcategory'].iloc[i]]] = 1\n",
    "    categoryEncodingVal[i][aliasesCat[valSet['category'].iloc[i]]] = 1\n",
    "    typeEncodingVal[i][aliasesType[valSet['type'].iloc[i]]] = 1\n",
    "    \n",
    "finalValData = np.concatenate((subCategoryEncodingVal, categoryEncodingVal, typeEncodingVal), axis=1)\n",
    "print(finalValData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a787270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPass(scale, gamma, kernel, features, labels, validation_features, validation_labels):\n",
    "    modelSubcategory = sksvm.SVC(kernel=kernel, \n",
    "                                C=scale, \n",
    "                                gamma=gamma,\n",
    "                                class_weight={\n",
    "                                        2:0.2700,\n",
    "                                        1:0.2994,\n",
    "                                        0:0.4305\n",
    "                                    }, \n",
    "                                probability=True, \n",
    "                                random_state=SEED,\n",
    "                                max_iter=10000)\n",
    "    modelSubcategory.fit(features, labels)\n",
    "    accuracy_score = modelSubcategory.score(validation_features, validation_labels)\n",
    "    return accuracy_score, modelSubcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e13d813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: rbf, C: 10.0000, Gamma: 1.0000 -> 0.5933333333333334\n",
      "Kernel: sigmoid, C: 10.0000, Gamma: 1.0000 -> 0.4633333333333333\n",
      "Accurecy: 59.3333\n",
      "SVC(C=10.0, class_weight={0: 0.4305, 1: 0.2994, 2: 0.27}, gamma=1.0,\n",
      "    max_iter=10000, probability=True, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    bestScore = 0\n",
    "    bestModel = None\n",
    "    for k in ['rbf', 'sigmoid']:\n",
    "        for s in np.linspace(1,1,1):\n",
    "            for c in np.linspace(10,10,1):\n",
    "                scoreValidation, model =  trainPass(c,s,k,\n",
    "                                          finalTrainData,\n",
    "                                          finalTrainLabel,\n",
    "                                          finalValData,\n",
    "                                          finalValLabel)\n",
    "                if scoreValidation > bestScore:\n",
    "                    bestModel = model\n",
    "                    bestScore = scoreValidation\n",
    "                print(f'Kernel: {k}, C: {c:.4f}, Gamma: {s:.4f} -> {scoreValidation}')\n",
    "    print(f\"Accurecy: {bestScore*100:.4f}\")\n",
    "    print(bestModel)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03e0ac",
   "metadata": {},
   "source": [
    "Best model: kernel='rbf', C=10, gamma=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08fa5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    joblib.dump(bestModel, 'categorySVCWeights.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bcbbf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max confidence: 71.5174%\n",
      "Min confidence: 38.2382%\n",
      "Mean confidence: 64.8531%\n",
      "Std confidence: 6.3313%\n"
     ]
    }
   ],
   "source": [
    "if not TRAINING:\n",
    "    svm = joblib.load('categorySVCWeights.pkl')\n",
    "else:\n",
    "    svm = bestModel\n",
    "    \n",
    "results = svm.predict_proba(finalValData)\n",
    "confidence = results[np.arange(results.shape[0]), np.argmax(results, axis=1)]*100\n",
    "\n",
    "print(f'Max confidence: {confidence.max():.4f}%')\n",
    "print(f'Min confidence: {confidence.min():.4f}%')\n",
    "print(f'Mean confidence: {confidence.mean():.4f}%')\n",
    "print(f'Std confidence: {confidence.std():.4f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
